## EaseMyAI RAG Chatbot

This project implements a **Retrieval-Augmented Generation (RAG)** chatbot using **Ollama + LangChain v0.3**, built to answer queries based on content from [EaseMyAI](https://easemyai.com).

---

### ğŸš€ Features

* ğŸ” Web scraping + chunking of EaseMyAI website
* ğŸ§  Local embeddings + FAISS vector store
* ğŸ¤– RAG pipeline with LLaMA3 or Phi-3 (via Ollama)
* ğŸ’¬ Streamlit-based chatbot interface
* ğŸ³ Dockerized + modular

---

### ğŸ—‚ï¸ Structure

```
app/
â”œâ”€â”€ ai/                # LLM, retriever, chain setup
â”œâ”€â”€ config/            # .env and settings
â”œâ”€â”€ easemyai_index/    # FAISS vector DB
â”œâ”€â”€ services/          # âš ï¸ One-time setup (scraping + indexing)
â”œâ”€â”€ main.py            # Streamlit UI
â”œâ”€â”€ cli.py            
```

---

### ğŸ³ Run via Docker

```bash
docker compose up --build
```

* Chatbot runs at: [http://localhost:8501](http://localhost:8501)

---

### ğŸ› ï¸ Stack

* LangChain v0.3
* Ollama (CPU-based LLMs)
* FAISS (Vector DB)
* Streamlit (UI)
* Docker Compose

---

### ğŸ§ª Example Query

> â€œWhat services does EaseMyAI provide?â€

---
